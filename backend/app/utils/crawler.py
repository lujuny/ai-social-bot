from playwright.async_api import async_playwright
import asyncio

async def scrape_weibo_hot():
    """
    æŠ“å–å¾®åšçƒ­æœæ¦œ (å‰10æ¡)
    """
    print("ğŸ•·ï¸ æ­£åœ¨çˆ¬å–å¾®åšçƒ­æœ...")
    results = []
    
    async with async_playwright() as p:
        # 1. å¯åŠ¨æµè§ˆå™¨ (headless=True è¡¨ç¤ºæ— å¤´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£)
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        try:
            # 2. è®¿é—®å¾®åšçƒ­æœæ‘˜è¦é¡µ (è¿™ä¸ªé¡µé¢ç›¸å¯¹æ¯”è¾ƒå¥½çˆ¬)
            await page.goto("https://s.weibo.com/top/summary", timeout=30000)
            
            # 3. ç­‰å¾…åˆ—è¡¨åŠ è½½å‡ºæ¥
            await page.wait_for_selector("td.td-02", timeout=5000)
            
            # 4. è·å–æ‰€æœ‰çƒ­æœæ¡ç›®
            items = await page.query_selector_all("td.td-02 a")
            
            # 5. æå–å‰15æ¡ (è·³è¿‡ç¬¬0æ¡ï¼Œå› ä¸ºé€šå¸¸æ˜¯ç½®é¡¶å¹¿å‘Š)
            for i, item in enumerate(items[1:16]): 
                title = await item.inner_text()
                href = await item.get_attribute("href")
                full_url = f"https://s.weibo.com{href}"
                
                # è¿‡æ»¤æ‰çº¯æ•°å­—æˆ–æ— æ•ˆæ ‡é¢˜
                if title and len(title) > 2:
                    results.append({
                        "title": title,
                        "platform": "Weibo",
                        "score": 90 - i,  # æ¨¡æ‹Ÿçƒ­åº¦åˆ†ï¼Œæ’åè¶Šé å‰åˆ†è¶Šé«˜
                        "url": full_url
                    })
                    
        except Exception as e:
            print(f"âŒ å¾®åšæŠ“å–å¤±è´¥: {e}")
        finally:
            await browser.close()
            
    return results

async def scrape_juejin_hot():
    """
    æŠ“å–ç¨€åœŸæ˜é‡‘æ–‡ç« æ¦œ (ç§‘æŠ€/ç¼–ç¨‹ç±»)
    """
    print("ğŸ•·ï¸ æ­£åœ¨çˆ¬å–æ˜é‡‘çƒ­æ¦œ...")
    results = []
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        try:
            # è®¿é—®æ˜é‡‘çƒ­æ¦œæ–‡ç« 
            await page.goto("https://juejin.cn/hot/articles", timeout=30000)
            
            # ç­‰å¾…æ–‡ç« æ ‡é¢˜å…ƒç´ åŠ è½½
            # æ³¨æ„ï¼šæ˜é‡‘çš„ç±»åå¯èƒ½ä¼šå˜ï¼Œè¿™é‡Œä½¿ç”¨æ¯”è¾ƒé€šç”¨çš„é€‰æ‹©å™¨
            await page.wait_for_selector(".article-item-link", timeout=5000)
            
            items = await page.query_selector_all(".article-item-link")
            
            for i, item in enumerate(items[:10]):
                title = await item.inner_text()
                href = await item.get_attribute("href")
                
                if title:
                    results.append({
                        "title": title,
                        "platform": "Juejin",
                        "score": 85 - i,
                        "url": f"https://juejin.cn{href}"
                    })
                    
        except Exception as e:
            print(f"âŒ æ˜é‡‘æŠ“å–å¤±è´¥: {e}")
        finally:
            await browser.close()
            
    return results

# è°ƒè¯•ç”¨ï¼šå¦‚æœç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶ï¼Œä¼šæµ‹è¯•ä¸€ä¸‹
if __name__ == "__main__":
    data = asyncio.run(scrape_weibo_hot())
    print(data)